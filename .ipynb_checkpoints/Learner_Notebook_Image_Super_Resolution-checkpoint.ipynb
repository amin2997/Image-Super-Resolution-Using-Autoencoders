{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Super Resolution using Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/high_res_v_low_res.jpg\" width=550px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Project Overview and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from scipy import ndimage, misc\n",
    "from skimage.transform import resize, rescale\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: What are Autoencoders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/autoencoder.jpg\">\n",
    "Credit: Autoencoder Schema by <a href=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\">Francois Chollet, 2016</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=center>Encoder Architecture</h4>\n",
    "<img src=\"images/encoder.png\" width=450px align=center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Build the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(256, 256, 3))\n",
    "l1 = Conv2D(64, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "\n",
    "l2 = Conv2D(64, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "\n",
    "l4 = Conv2D(128, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "\n",
    "l5 = Conv2D(128, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "\n",
    "# default pool_size=(2,2) which will reduce the conv2D in half.\n",
    "l6 = MaxPooling2D(padding='same')(l5) \n",
    "\n",
    "l7 = Conv2D(256, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l6)\n",
    "\n",
    "encoder = Model(input_img, l7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "=================================================================\n",
      "Total params: 555,328\n",
      "Trainable params: 555,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Build the Decoder to Complete the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/decoder.png\" width=450px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(256, 256, 3))\n",
    "l1 = Conv2D(64, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
    "\n",
    "l2 = Conv2D(64, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l1)\n",
    "\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "\n",
    "l4 = Conv2D(128, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l3)\n",
    "\n",
    "l5 = Conv2D(128, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l4)\n",
    "\n",
    "# default pool_size=(2,2) which will reduce the conv2D in half.\n",
    "l6 = MaxPooling2D(padding='same')(l5) \n",
    "\n",
    "l7 = Conv2D(256, (3,3), padding='same', activation='relu',\n",
    "            activity_regularizer=regularizers.l1(10e-10))(l6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 64) 1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 147584      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 128 295040      up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 128 147584      conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 128, 128 0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 128 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 64) 73792       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 256, 64) 0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 3)  1731        add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,110,403\n",
      "Trainable params: 1,110,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#starting the decoder with upscaling the last conv2D layer.\n",
    "\n",
    "l8 = UpSampling2D()(l7) # reverse of maxpool. default size=(2,2) which will double size (2x)\n",
    "\n",
    "l9 = Conv2D(128, (3,3), padding='same', activation='relu', \n",
    "            activity_regularizer=regularizers.l1(10e-10))(l8)\n",
    "\n",
    "l10 = Conv2D(128, (3,3), padding='same', activation='relu', \n",
    "            activity_regularizer=regularizers.l1(10e-10))(l9)\n",
    "\n",
    "# Sharing knowledge between the encoder and decoder resolved the vanishing gradient problem,\n",
    "# which is caused everytime you go deep and deep in neural network\n",
    "l11 = add([l5,l10])\n",
    "l12 = UpSampling2D()(l11)\n",
    "\n",
    "l13 = Conv2D(64, (3,3), padding='same', activation='relu', \n",
    "            activity_regularizer=regularizers.l1(10e-10))(l12)\n",
    "\n",
    "l14 = Conv2D(64, (3,3), padding='same', activation='relu', \n",
    "            activity_regularizer=regularizers.l1(10e-10))(l13)\n",
    "\n",
    "l15 = add([l14,l2])\n",
    "\n",
    "decoded = Conv2D(3, (3,3), padding='same', activation='relu', \n",
    "            activity_regularizer=regularizers.l1(10e-10))(l15)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Create Dataset and Specify Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_batches(just_load_dataset=False):\n",
    "\n",
    "    batches = 256 \n",
    "\n",
    "    batch = 0 \n",
    "    batch_nb = 0 \n",
    "    max_batches = -1 \n",
    "    \n",
    "    ep = 4 \n",
    "\n",
    "    images = []\n",
    "    x_train_n = []\n",
    "    x_train_down = []\n",
    "    \n",
    "    x_train_n2 = [] \n",
    "    x_train_down2 = []\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(\"/home/rhyme/Desktop/Project/data/cars_train\"):\n",
    "        for filename in filenames:\n",
    "            if re.search(\"\\.(jpg|jpeg|JPEG|png|bmp|tiff)$\", filename):\n",
    "                if batch_nb == max_batches: \n",
    "                    return x_train_n2, x_train_down2\n",
    "                filepath = os.path.join(root, filename)\n",
    "                image = pyplot.imread(filepath)\n",
    "                if len(image.shape) > 2:\n",
    "                        \n",
    "                    image_resized = resize(image, (256, 256))\n",
    "                    x_train_n.append(image_resized)\n",
    "                    x_train_down.append(rescale(rescale(image_resized, 0.5), 2.0))\n",
    "                    batch += 1\n",
    "                    if batch == batches:\n",
    "                        batch_nb += 1\n",
    "\n",
    "                        x_train_n2 = np.array(x_train_n)\n",
    "                        x_train_down2 = np.array(x_train_down)\n",
    "                        \n",
    "                        if just_load_dataset:\n",
    "                            return x_train_n2, x_train_down2\n",
    "                        \n",
    "                        print('Training batch', batch_nb, '(', batches, ')')\n",
    "\n",
    "                        autoencoder.fit(x_train_down2, x_train_n2,\n",
    "                            epochs=ep,\n",
    "                            batch_size=10,\n",
    "                            shuffle=True,\n",
    "                            validation_split=0.15)\n",
    "                    \n",
    "                        x_train_n = []\n",
    "                        x_train_down = []\n",
    "                    \n",
    "                        batch = 0\n",
    "\n",
    "    return x_train_n2, x_train_down2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Load the Dataset and Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhyme/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/rhyme/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/rhyme/.local/lib/python2.7/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n"
     ]
    }
   ],
   "source": [
    "x_train_n, x_train_down = train_batches(just_load_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('/home/rhyme/Desktop/Project/data/sr.img_net.mse.final_model5.no_patch.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Model Predictions and Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights(r'/home/rhyme/Desktop/Project/data/encoder_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64, 64, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.shape # encoded representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1 = np.clip(autoencoder.predict(x_train_down), 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
